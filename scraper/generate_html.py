from datetime import datetime, date, timedelta # datetime: ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—ãƒ»æ•´å½¢ã™ã‚‹ãŸã‚ã«ä½¿ã„ã¾ã™ï¼ˆç™ºè¡Œæ—¥æ™‚ã®è¡¨ç¤ºç”¨ï¼‰ã€‚
import os # os: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å‹•çš„ã«ç”Ÿæˆã™ã‚‹ãŸã‚ã«ä½¿ã„ã¾ã™ã€‚
import re # re: æ­£è¦è¡¨ç¾ï¼ˆæ–‡å­—åˆ—å‡¦ç†ï¼‰ã‚’è¡Œã†Pythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚
# æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼ˆä»Šæ—¥åˆ†ãŒDBã«ç„¡ã„ã¨ãã ã‘ä½¿ã†ï¼‰
from scraper.fetch_news import get_all_headlines
# DBã‹ã‚‰ headline ã‚’å–ã‚‹
from db.settings import SessionLocal
from db.models import Headline

# ç•ªå·ä»˜ããƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç•ªå·ã‚’é™¤å»ã™ã‚‹ï¼ˆ"1â—‹â—‹" â†’ "â—‹â—‹"ï¼‰
def remove_leading_number(text):
    if isinstance(text, str) and text[:1].isdigit(): # isdigit() ã§å…ˆé ­æ–‡å­—ãŒæ•°å­—ã‹ã©ã†ã‹ç¢ºèªã€‚
        return text[1:] # text[1:] ã§ãã®1æ–‡å­—ç›®ã‚’å–ã‚Šé™¤ã„ãŸæ–‡å­—åˆ—ã‚’è¿”ã™ã€‚
    return text

# DBã‹ã‚‰æœ€è¿‘ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def _fetch_from_db_for_recent(days: int = 1, max_per_source: int = 5):
    """
    ç›´è¿‘ days æ—¥ã«è©²å½“ã™ã‚‹ headlines ã‚’DBã‹ã‚‰å–å¾—ã—ã¦ã€{source: [Headline,...]}ã§è¿”ã™ã€‚
    """
    session = SessionLocal()
    try:
        since = date.today() - timedelta(days=days-1)  # ä»Šæ—¥ã‚’å«ã‚€ days åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        rows = (
            session.query(Headline)
            .filter(Headline.date >= since)
            .order_by(Headline.id.desc())
            .all()
        )
        bucket = {}
        for r in rows:
            bucket.setdefault(r.source, []) # bucket.setdefault() ã§ã‚½ãƒ¼ã‚¹åˆ¥ã«åˆ†é¡
            # ã‚½ãƒ¼ã‚¹ã”ã¨ã«æœ€å¤§ max_per_source ä»¶ã¾ã§
            if (max_per_source is None) or (len(bucket[r.source]) < max_per_source):
                bucket[r.source].append(r)
        return bucket
    finally:
        session.close()

# HTMLå‡ºåŠ›é–¢æ•°
def generate_html(main_path, archive_path): # ã“ã®é–¢æ•°ã§ã¯ã€HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’2ã‹æ‰€ã«ä¿å­˜ã—ã¾ã™ï¼šmain_path: æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ç”¨ï¼ˆä¾‹ï¼špublic/news_report.htmlï¼‰archive_path: å±¥æ­´ä¿å­˜ç”¨ï¼ˆä¾‹ï¼špublic/history/news_2025-07-27.htmlï¼‰
    # è¦‹å‡ºã—ã¨æ—¥æ™‚ã®å–å¾—
    all_news = get_all_headlines()  # [(source_name, [(title, url), ...]), ...]
    # æ—¥ä»˜ãƒ»æ™‚åˆ»ã®å–å¾—ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    now = datetime.now()
    now_str = now.strftime('%Y/%m/%d %H:%M') # now_str: HTMLã«è¡¨ç¤ºã™ã‚‹ç™ºè¡Œæ—¥æ™‚ï¼ˆäººé–“å‘ã‘ï¼‰
    date_str = now.strftime('%Y-%m-%d') # date_str: ãƒ•ã‚¡ã‚¤ãƒ«åã‚„ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ä½¿ã†ï¼ˆæ©Ÿæ¢°å‘ã‘ï¼‰

    # ä¾‹: ç›´è¿‘2æ—¥ãƒ»å„ã‚½ãƒ¼ã‚¹æœ€å¤§10ä»¶è¡¨ç¤ºï¼ˆä¸Šé™ãªã—ã«ã™ã‚‹ãªã‚‰ max_per_source=Noneï¼‰
    bucket = _fetch_from_db_for_recent(days=7, max_per_source=5)

    # ã‚‚ã—ä»Šæ—¥åˆ†ãŒDBã«1ä»¶ã‚‚ãªã‘ã‚Œã°ã€æ—¢å­˜ã®ãƒ•ãƒ­ãƒ¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    # ï¼ˆåˆå›å®Ÿè¡Œã‚„åé›†å¤±æ•—æ™‚ã®ä¿é™ºï¼‰
    use_db = True
    if not bucket:
        use_db = False
        all_news = get_all_headlines()  # [(source, [(title,url),..]),..]

    # è¡¨ç¤ºã—ãŸã„ã‚½ãƒ¼ã‚¹é †ï¼ˆä»»æ„ï¼‰ï¼šDBã®ã‚­ãƒ¼é †ã ã¨ãƒãƒ©ã¤ãã®ã§å›ºå®šé †ã‚’ç”¨æ„
    preferred_sources = [
        "NHKãƒ‹ãƒ¥ãƒ¼ã‚¹", "æ™‚äº‹é€šä¿¡", "ITmedia", "æ±æ´‹çµŒæ¸ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³", "ãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰ãƒ»ã‚ªãƒ³ãƒ©ã‚¤ãƒ³",
        "ABEMA TIMES", "Sponichi Annex", "INTERNET Watch", "BBCãƒ‹ãƒ¥ãƒ¼ã‚¹", "CNN.co.jp"
    ]
    if use_db:
        ordered_sources = [s for s in preferred_sources if s in bucket] \
                          + [s for s in bucket.keys() if s not in preferred_sources]
    else:
        ordered_sources = [s for s, _ in all_news]
    # DBãƒ¢ãƒ¼ãƒ‰ãªã‚‰ã€bucketã«å­˜åœ¨ã™ã‚‹ã‚‚ã®ã ã‘é †åºé©ç”¨
    # ordered_sources = (
    #     [s for s in preferred_sources if (use_db and s in bucket)]
    #     if use_db else
    #     [s for s, _ in all_news]
    # )

    # HTMLã®å†’é ­ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰
    html = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆ{date_str}ï¼‰</title>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {{
            font-family: 'Noto Sans JP', sans-serif;
            margin: 0;
            padding: 2rem 1rem;
            background-color: #f0f2f5;
            color: #333;
        }}
        .container {{
            max-width: 720px;
            margin: auto;
            background: #fff;
            padding: 2rem;
            border-radius: 12px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.05);
        }}
        h1 {{
            font-size: 1.8rem;
            margin-bottom: 0.5rem;
            color: #111;
        }}
        .date {{
            font-size: 0.9rem;
            color: #888;
            margin-bottom: 1.5rem;
        }}
        ol {{
            padding-left: 1.2rem;
        }}
        li {{
            margin-bottom: 1rem;
            line-height: 1.6;
        }}
        a {{
            color: #007acc;
            text-decoration: none;
            font-weight: bold;
        }}
        a:hover {{
            text-decoration: underline;
        }}
        footer {{
            margin-top: 3rem;
            font-size: 0.85rem;
            text-align: center;
            color: #aaa;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“° ä»Šæ—¥ã®ä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆ{date_str}ï¼‰</h1>
        <p class="date">ç™ºè¡Œæ—¥æ™‚ï¼š{now_str}</p>
        <ol>
"""
# ãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œï¼ˆ<meta name="viewport">ã‚ã‚Šï¼‰
# <ol>ï¼šé †åºä»˜ããƒªã‚¹ãƒˆï¼ˆè‡ªå‹•ã§ã€Œ1.ã€ã€Œ2.ã€ã¨ç•ªå·ãŒä»˜ãã¾ã™ï¼‰

    # --- æœ¬ä½“æç”» ---
    # DBãƒ¢ãƒ¼ãƒ‰ï¼šbucket[source] ã¯ Headline ã®é…åˆ—
    if use_db:
        for source_name in ordered_sources:
            items = bucket.get(source_name, [])
            if not items:
                continue
            html += f"<h2>{source_name}</h2>\n<ol>\n"
            for r in items: # r ã¯ Headline ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
                clean_title = remove_leading_number(r.title or "")
                html += f'  <li><a href="{r.url}" target="_blank" rel="noopener">{clean_title}</a>'
                # è¦ç´„
                if r.summary: # r.summary ã‚„ r.keywords ã¯DBã«ä¿å­˜ã•ã‚ŒãŸæƒ…å ±
                    html += f'<div class="summary">{r.summary}</div>'
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š â†’ #ã‚¿ã‚°é¢¨ï¼‰
                if r.keywords:
                    tags = ' #'.join([k.strip() for k in r.keywords.split(',') if k.strip()]) # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯ # ã‚’ã¤ã‘ã¦ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°é¢¨ã«è¡¨ç¤º
                    if tags:
                        html += f'<div class="keywords">#{tags}</div>'
                html += "</li>\n"
            html += "</ol>\n"
    else:

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ—çµæœã‚’ãã®ã¾ã¾è¡¨ç¤ºï¼ˆè¦ç´„ã¯å‡ºãªã„ï¼‰
        # å„ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ã‚’ <li> ã‚¿ã‚°ã¨ã—ã¦HTMLãƒªã‚¹ãƒˆã«è¿½åŠ 
        for source_name, headlines in all_news:
            html += f"<h2>{source_name}</h2>\n<ol>\n"
            for title, url in headlines:
                clean_title = remove_leading_number(title) # remove_leading_number(...)ï¼šç•ªå·ã‚’å‰Šé™¤
                html += f'  <li><a href="{url}" target="_blank" rel="noopener">{clean_title}</a></li>\n'
            html += "</ol>\n"

    # HTMLã®æœ«å°¾ã‚’é–‰ã˜ã‚‹
    html += """    <footer>æä¾›ï¼šã¾ã„ã«ã‚…ã€œ</footer>
</body>
</html>"""

    # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
    for path in [main_path, archive_path]:
        os.makedirs(os.path.dirname(path), exist_ok=True) # os.makedirs(...): ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è‡ªå‹•ä½œæˆï¼ˆhistory/ãªã©ï¼‰
        with open(path, 'w', encoding='utf-8') as f: # open(..., 'w'): ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ããƒ¢ãƒ¼ãƒ‰ã§é–‹ãã€UTF-8ã§ä¿å­˜
            f.write(html)

    print(f"âœ… HTMLç”Ÿæˆå®Œäº†: {main_path}")
    print(f"ğŸ“¦ å±¥æ­´ä¿å­˜å®Œäº†: {archive_path}")

# å®Ÿè¡Œéƒ¨åˆ†
if __name__ == "__main__": # __name__ == "__main__"ï¼šã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸã¨ãã ã‘ä¸‹è¨˜ã‚’å®Ÿè¡Œ
    # main_path ã¨ archive_path ã®è¨­å®š
    base_dir = os.path.dirname(__file__) # os.path.dirname(__file__)ï¼šã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    public_dir = os.path.join(base_dir, "../public") # ../public: HTMLã‚’ä¿å­˜ã™ã‚‹å…¬é–‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    history_dir = os.path.join(public_dir, "history") # history: æ—¥ä»˜ã”ã¨ã«å±¥æ­´ã‚’æ®‹ã™ãŸã‚ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€

    today_str = datetime.now().strftime('%Y-%m-%d')
    latest_path = os.path.join(public_dir, "news_report.html") # latest_path: ä¸Šæ›¸ãã•ã‚Œã‚‹æœ€æ–°ç‰ˆHTML
    archive_path = os.path.join(history_dir, f"news_{today_str}.html") # archive_path: æ¯æ—¥åˆ¥åã§ä¿å­˜ã•ã‚Œã‚‹å±¥æ­´HTML

    generate_html(latest_path, archive_path)
